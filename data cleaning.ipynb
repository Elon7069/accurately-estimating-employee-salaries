# Overview of the dataset
print("Dataset Overview:")
print(data.info())

# Checking for missing values
print("\nMissing Values Count:")
print(data.isnull().sum())

# Checking for duplicates
print("\nDuplicate Rows Count:", data.duplicated().sum())

# Display a summary of statistics for numerical features
print("\nSummary Statistics for Numerical Features:")
print(data.describe())

# Display unique values for categorical features
categorical_cols = data.select_dtypes(include=['object']).columns
for col in categorical_cols:
    print(f"\nUnique Values in {col}: {data[col].nunique()}")


# Filling missing numerical data with mean or median
numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns
for col in numerical_cols:
    if data[col].isnull().sum() > 0:
        data[col].fillna(data[col].median(), inplace=True)  # Replace with 'mean' if required

# Filling missing categorical data with mode
for col in categorical_cols:
    if data[col].isnull().sum() > 0:
        data[col].fillna(data[col].mode()[0], inplace=True)

print("\nMissing values handled successfully!")


# Remove duplicate rows
data.drop_duplicates(inplace=True)
print("\nDuplicates removed successfully!")

# Standardizing column names
data.columns = data.columns.str.lower().str.replace(' ', '_').str.replace(r'[^\w]', '', regex=True)
print("\nColumn names standardized successfully!")

# Fix incorrect categorical values
for col in categorical_cols:
    print(f"\nUnique values in {col} before cleanup: {data[col].unique()}")
    # Replace incorrect categories (Example: 'femail' -> 'female')
    data[col] = data[col].replace({'femail': 'female', 'Male ': 'Male'})

# Fix numerical anomalies (Example: Age < 0 or Salary < 0)
data = data[(data['age'] >= 18) & (data['age'] <= 65)]  # Filtering valid age range
data = data[data['salary'] >= 0]  # Ensuring no negative salaries
print("\nAnomalous data corrected successfully!")

# Replace extreme outliers with boundary values (winsorization)
def handle_outliers(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return series.clip(lower_bound, upper_bound)

for col in numerical_cols:
    data[col] = handle_outliers(data[col])

print("\nOutliers handled successfully!")

# Convert date columns to a standard format
if 'hire_date' in data.columns:
    data['hire_date'] = pd.to_datetime(data['hire_date'], errors='coerce')
    print("\nDate column standardized successfully!")

# Drop columns with >50% missing data
missing_percentage = data.isnull().mean() * 100
columns_to_drop = missing_percentage[missing_percentage > 50].index
data.drop(columns=columns_to_drop, axis=1, inplace=True)

# Drop irrelevant columns
data.drop(['employee_id'], axis=1, inplace=True)  # Example: Drop unique identifier columns
print("\nIrrelevant and redundant columns dropped successfully!")

# Convert all text to lowercase for uniformity
for col in categorical_cols:
    data[col] = data[col].str.lower()

# Trim extra spaces
for col in categorical_cols:
    data[col] = data[col].str.strip()

print("\nCategorical data inconsistencies resolved successfully!")

# Save the cleaned dataset to a new CSV file
data.to_csv('cleaned_dataset.csv', index=False)
print("\nCleaned dataset saved successfully!")







